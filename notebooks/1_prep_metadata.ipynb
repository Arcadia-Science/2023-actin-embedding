{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb66e04c",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook was used to prepare the UniProt `features_file.tsv` to use for Cluster Mode of the ProteinCartography pipeline.\n",
    "\n",
    "In order to use this notebook, you must activate the `2023-actin-embedding` conda env. You should also be within the `2023-actin-embedding/notebooks` folder.\n",
    "\n",
    "The original list of actins was generated in our [Defining Actin](https://research.arcadiascience.com/pub/idea-defining-actin/release/4?readingCollection=9a516d32) pub and the corresponding [Actin Prediction](https://github.com/Arcadia-Science/2022-actin-prediction) pipeline, where we did a protein BLAST search for 50,000 matches to [human beta-actin](https://www.uniprot.org/uniprotkb/P60709/entry). The list can be found in this [Zenodo archive](https://zenodo.org/records/7384393).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d627755d",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First make sure you are in the correct directory `2023-actin-embedding/notebooks` and that you have the correct conda environment activated by running: \n",
    "``` \n",
    "conda activate 2023-actin-embedding\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70788f9a",
   "metadata": {},
   "source": [
    "Import dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e2e5aca-1954-4264-b2d2-05c2d0fdd72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "PC_path = \"./../../ProteinCartography/ProteinCartography\"\n",
    "input_path = \"./../input\"\n",
    "sys.path.append(PC_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74773f27",
   "metadata": {},
   "source": [
    "Prepare directories. Once these are prepared, place the 2022-actin-prediction-blasoutputs.txt files in the `~/Actin/prep` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c84f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./../output/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a6e7d3",
   "metadata": {},
   "source": [
    "## Map Refseq IDs\n",
    "\n",
    "The output of BLAST is a list of RefSeq IDs, but ProteinCartography and the AlphaFold database reference proteins based on their Accessions/UniProt IDs. This step converts RefSeq IDs to Accessions/UniProt IDs and then uses them to download the required metadata file. Note that I split this into 2 batches as the single batch was too large and continually failed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527671f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/brae/2023-actin-embedding/notebooks/./../../ProteinCartography/ProteinCartography/map_refseqids.py\", line 228, in <module>\n",
      "    main()\n",
      "  File \"/Users/brae/2023-actin-embedding/notebooks/./../../ProteinCartography/ProteinCartography/map_refseqids.py\", line 221, in main\n",
      "    map_refseqids_bioservices(input_file, output_file, query_dbs)\n",
      "  File \"/Users/brae/2023-actin-embedding/notebooks/./../../ProteinCartography/ProteinCartography/map_refseqids.py\", line 96, in map_refseqids_bioservices\n",
      "    results = uniprot.mapping(db, \"UniProtKB\", query=\",\".join(ids))\n",
      "  File \"/Users/brae/miniconda3/envs/2023-actin-embedding/lib/python3.9/site-packages/bioservices/uniprot.py\", line 493, in mapping\n",
      "    time.sleep(polling_interval_seconds)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Set paths\n",
    "\n",
    "map_refseqids = os.path.join(PC_path, \"map_refseqids.py\")\n",
    "input_map_refseqids1 = os.path.join(\n",
    "    input_path, \"2022-actin-prediction-blastoutputs1.txt\"\n",
    ")\n",
    "input_map_refseqids2 = os.path.join(\n",
    "    input_path, \"2022-actin-prediction-blastoutputs1.txt\"\n",
    ")\n",
    "input_map_refseqids3 = os.path.join(\n",
    "    input_path, \"2022-actin-prediction-blastoutputs3.txt\"\n",
    ")\n",
    "input_map_refseqids4 = os.path.join(\n",
    "    input_path, \"2022-actin-prediction-blastoutputs4.txt\"\n",
    ")\n",
    "output_map_refseqids1 = os.path.join(input_path, \"blastoutput_uniprot1.txt\")\n",
    "output_map_refseqids2 = os.path.join(input_path, \"blastoutput_uniprot2.txt\")\n",
    "output_map_refseqids3 = os.path.join(input_path, \"blastoutput_uniprot3.txt\")\n",
    "output_map_refseqids4 = os.path.join(input_path, \"blastoutput_uniprot4.txt\")\n",
    "\n",
    "# Batch 1\n",
    "os.system(\n",
    "    f\"python {map_refseqids} -i {input_map_refseqids1} -o {output_map_refseqids1} -s bioservices\"\n",
    ")\n",
    "\n",
    "# Batch 2\n",
    "os.system(\n",
    "    f\"python {map_refseqids} -i {input_map_refseqids2} -o {output_map_refseqids2}\"\n",
    ")\n",
    "\n",
    "# Batch 3\n",
    "os.system(\n",
    "    f\"python {map_refseqids} -i {input_map_refseqids3} -o {output_map_refseqids3}\"\n",
    ")\n",
    "\n",
    "# Batch 4\n",
    "os.system(\n",
    "    f\"python {map_refseqids} -i {input_map_refseqids4} -o {output_map_refseqids4}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "360299b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_refseqids = os.path.join(PC_path, \"map_refseqids.py\")\n",
    "input_map_refseqids1 = os.path.join(\n",
    "    input_path, \"2022-actin-prediction-blastoutputs1.txt\"\n",
    ")\n",
    "output_map_refseqids1 = os.path.join(input_path, \"blastoutput_uniprot1.txt\")\n",
    "\n",
    "# Batch 1\n",
    "os.system(\n",
    "    f\"python {map_refseqids} -i {input_map_refseqids1} -o {output_map_refseqids1}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be4a9e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_map_refseqids2 = os.path.join(\n",
    "    input_path, \"2022-actin-prediction-blastoutputs2.txt\"\n",
    ")\n",
    "output_map_refseqids2 = os.path.join(input_path, \"blastoutput_uniprot2.txt\")\n",
    "\n",
    "# Batch 2\n",
    "os.system(\n",
    "    f\"python {map_refseqids} -i {input_map_refseqids2} -o {output_map_refseqids2}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a7fc0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_map_refseqids3 = os.path.join(\n",
    "    input_path, \"2022-actin-prediction-blastoutputs3.txt\"\n",
    ")\n",
    "output_map_refseqids3 = os.path.join(input_path, \"blastoutput_uniprot3.txt\")\n",
    "\n",
    "# Batch 3\n",
    "os.system(\n",
    "    f\"python {map_refseqids} -i {input_map_refseqids3} -o {output_map_refseqids3}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93e852b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_map_refseqids4 = os.path.join(\n",
    "    input_path, \"2022-actin-prediction-blastoutputs4.txt\"\n",
    ")\n",
    "output_map_refseqids4 = os.path.join(input_path, \"blastoutput_uniprot4.txt\")\n",
    "\n",
    "# Batch 4\n",
    "os.system(\n",
    "    f\"python {map_refseqids} -i {input_map_refseqids4} -o {output_map_refseqids4}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e31249",
   "metadata": {},
   "source": [
    "## Download UniProt metadata\n",
    "\n",
    "After obtaining UniProt IDs, we use them to download metadata from UniProt. This data will be the bulk of the UniProt features file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fae17cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file already exists at this location. Aborting.\n",
      "Output file already exists at this location. Aborting.\n",
      ">> Starting batch 1 of 23\n",
      "downloaded 300 / 6873 hits for batch 1\n",
      ">> Starting batch 2 of 23\n",
      "downloaded 300 / 6873 hits for batch 2\n",
      ">> Starting batch 3 of 23\n",
      "downloaded 300 / 6873 hits for batch 3\n",
      ">> Starting batch 4 of 23\n",
      "downloaded 300 / 6873 hits for batch 4\n",
      ">> Starting batch 5 of 23\n",
      "downloaded 300 / 6873 hits for batch 5\n",
      ">> Starting batch 6 of 23\n",
      "downloaded 300 / 6873 hits for batch 6\n",
      ">> Starting batch 7 of 23\n",
      "downloaded 300 / 6873 hits for batch 7\n",
      ">> Starting batch 8 of 23\n",
      "downloaded 300 / 6873 hits for batch 8\n",
      ">> Starting batch 9 of 23\n",
      "downloaded 300 / 6873 hits for batch 9\n",
      ">> Starting batch 10 of 23\n",
      "downloaded 300 / 6873 hits for batch 10\n",
      ">> Starting batch 11 of 23\n",
      "downloaded 300 / 6873 hits for batch 11\n",
      ">> Starting batch 12 of 23\n",
      "downloaded 300 / 6873 hits for batch 12\n",
      ">> Starting batch 13 of 23\n",
      "downloaded 300 / 6873 hits for batch 13\n",
      ">> Starting batch 14 of 23\n",
      "downloaded 300 / 6873 hits for batch 14\n",
      ">> Starting batch 15 of 23\n",
      "downloaded 300 / 6873 hits for batch 15\n",
      ">> Starting batch 16 of 23\n",
      "downloaded 300 / 6873 hits for batch 16\n",
      ">> Starting batch 17 of 23\n",
      "downloaded 300 / 6873 hits for batch 17\n",
      ">> Starting batch 18 of 23\n",
      "downloaded 300 / 6873 hits for batch 18\n",
      ">> Starting batch 19 of 23\n",
      "downloaded 300 / 6873 hits for batch 19\n",
      ">> Starting batch 20 of 23\n",
      "downloaded 300 / 6873 hits for batch 20\n",
      ">> Starting batch 21 of 23\n",
      "downloaded 300 / 6873 hits for batch 21\n",
      ">> Starting batch 22 of 23\n",
      "downloaded 300 / 6873 hits for batch 22\n",
      ">> Starting batch 23 of 23\n",
      "downloaded 273 / 6873 hits for batch 23\n",
      ">> Starting batch 1 of 25\n",
      "downloaded 300 / 7320 hits for batch 1\n",
      ">> Starting batch 2 of 25\n",
      "downloaded 300 / 7320 hits for batch 2\n",
      ">> Starting batch 3 of 25\n",
      "downloaded 300 / 7320 hits for batch 3\n",
      ">> Starting batch 4 of 25\n",
      "downloaded 300 / 7320 hits for batch 4\n",
      ">> Starting batch 5 of 25\n",
      "downloaded 300 / 7320 hits for batch 5\n",
      ">> Starting batch 6 of 25\n",
      "downloaded 300 / 7320 hits for batch 6\n",
      ">> Starting batch 7 of 25\n",
      "downloaded 300 / 7320 hits for batch 7\n",
      ">> Starting batch 8 of 25\n",
      "downloaded 300 / 7320 hits for batch 8\n",
      ">> Starting batch 9 of 25\n",
      "downloaded 300 / 7320 hits for batch 9\n",
      ">> Starting batch 10 of 25\n",
      "downloaded 300 / 7320 hits for batch 10\n",
      ">> Starting batch 11 of 25\n",
      "downloaded 300 / 7320 hits for batch 11\n",
      ">> Starting batch 12 of 25\n",
      "downloaded 300 / 7320 hits for batch 12\n",
      ">> Starting batch 13 of 25\n",
      "downloaded 300 / 7320 hits for batch 13\n",
      ">> Starting batch 14 of 25\n",
      "downloaded 300 / 7320 hits for batch 14\n",
      ">> Starting batch 15 of 25\n",
      "downloaded 300 / 7320 hits for batch 15\n",
      ">> Starting batch 16 of 25\n",
      "downloaded 300 / 7320 hits for batch 16\n",
      ">> Starting batch 17 of 25\n",
      "downloaded 300 / 7320 hits for batch 17\n",
      ">> Starting batch 18 of 25\n",
      "downloaded 300 / 7320 hits for batch 18\n",
      ">> Starting batch 19 of 25\n",
      "downloaded 300 / 7320 hits for batch 19\n",
      ">> Starting batch 20 of 25\n",
      "downloaded 300 / 7320 hits for batch 20\n",
      ">> Starting batch 21 of 25\n",
      "downloaded 300 / 7320 hits for batch 21\n",
      ">> Starting batch 22 of 25\n",
      "downloaded 300 / 7320 hits for batch 22\n",
      ">> Starting batch 23 of 25\n",
      "downloaded 300 / 7320 hits for batch 23\n",
      ">> Starting batch 24 of 25\n",
      "downloaded 300 / 7320 hits for batch 24\n",
      ">> Starting batch 25 of 25\n",
      "downloaded 120 / 7320 hits for batch 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set paths\n",
    "\n",
    "fetch_uniprot_metadata = os.path.join(PC_path, \"fetch_uniprot_metadata.py\")\n",
    "output_uniprot_metadata1 = os.path.join(input_path, \"uniprot_features1.tsv\")\n",
    "output_uniprot_metadata2 = os.path.join(input_path, \"uniprot_features2.tsv\")\n",
    "output_uniprot_metadata3 = os.path.join(input_path, \"uniprot_features3.tsv\")\n",
    "output_uniprot_metadata4 = os.path.join(input_path, \"uniprot_features4.tsv\")\n",
    "\n",
    "# Batch 1\n",
    "os.system(\n",
    "    f\"python {fetch_uniprot_metadata} -i {output_map_refseqids1} -o {output_uniprot_metadata1}\"\n",
    ")\n",
    "\n",
    "# Batch 2\n",
    "os.system(\n",
    "    f\"python {fetch_uniprot_metadata} -i {output_map_refseqids2} -o {output_uniprot_metadata2}\"\n",
    ")\n",
    "\n",
    "# Batch 3\n",
    "os.system(\n",
    "    f\"python {fetch_uniprot_metadata} -i {output_map_refseqids3} -o {output_uniprot_metadata3}\"\n",
    ")\n",
    "\n",
    "# Batch 4\n",
    "os.system(\n",
    "    f\"python {fetch_uniprot_metadata} -i {output_map_refseqids4} -o {output_uniprot_metadata4}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9100365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge batched files\n",
    "uniprot_features1 = pd.read_csv(\"../input/uniprot_features1.tsv\", sep=\"\\t\")\n",
    "uniprot_features2 = pd.read_csv(\"../input/uniprot_features2.tsv\", sep=\"\\t\")\n",
    "uniprot_features3 = pd.read_csv(\"../input/uniprot_features3.tsv\", sep=\"\\t\")\n",
    "uniprot_features4 = pd.read_csv(\"../input/uniprot_features4.tsv\", sep=\"\\t\")\n",
    "uniprot_features_combined = pd.concat([uniprot_features1, uniprot_features2, uniprot_features3, uniprot_features4])\n",
    "uniprot_features_combined = uniprot_features_combined.drop_duplicates(subset=\"protid\", keep=\"first\")\n",
    "\n",
    "# Save uniprot_features file\n",
    "uniprot_features_combined.to_csv(\n",
    "    \"../input/uniprot_features_combined.tsv\", sep=\"\\t\", index=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf106b",
   "metadata": {},
   "source": [
    "## Filter UniProt hits\n",
    "\n",
    "We filtered UniProt hits based on fragment status and whether or not the UniProt entry was active using the `filter_uniprot_hits.py` script from [ProteinCartography](https://github.com/Arcadia-Science/ProteinCartography).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dfade35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set paths\n",
    "filter_uniprot_hits = os.path.join(PC_path, \"filter_uniprot_hits.py\")\n",
    "output_filtered_list = os.path.join(input_path, \"features_filter.tsv\")\n",
    "input_uniprot_features = os.path.join(input_path, \"uniprot_features_combined.tsv\")\n",
    "\n",
    "os.system(\n",
    "    f\"python {filter_uniprot_hits} -i {input_uniprot_features} -o {output_filtered_list}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47328a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P32392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q3UBP6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A5A8EBC0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N1PEJ5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A8J6DHP0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>L8HGQ4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18900</th>\n",
       "      <td>L8HSP9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18901</th>\n",
       "      <td>L8Y6K9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18902</th>\n",
       "      <td>R1CYF7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18903</th>\n",
       "      <td>T2MFE1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18904 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           protid\n",
       "0          P32392\n",
       "1          Q3UBP6\n",
       "2      A0A5A8EBC0\n",
       "3          N1PEJ5\n",
       "4      A0A8J6DHP0\n",
       "...           ...\n",
       "18899      L8HGQ4\n",
       "18900      L8HSP9\n",
       "18901      L8Y6K9\n",
       "18902      R1CYF7\n",
       "18903      T2MFE1\n",
       "\n",
       "[18904 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Renames first column to protid\n",
    "features_filtered = pd.read_csv(output_filtered_list, sep=\"\\t\", names=[\"protid\"])\n",
    "\n",
    "# Save uniprot_features file\n",
    "features_filtered.to_csv(output_filtered_list, sep=\"\\t\", index=None)\n",
    "display(features_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "431adb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep paths\n",
    "output_filter_hits = os.path.join(input_path, \"uniprot_features_filtered.tsv\")\n",
    "\n",
    "# Apply filter\n",
    "uniprot_features_combined = pd.read_csv(\"../input/uniprot_features_combined.tsv\", sep=\"\\t\")\n",
    "uniprot_features_filtered = uniprot_features_combined.merge(\n",
    "    features_filtered, on=\"protid\", how=\"inner\"\n",
    ")\n",
    "\n",
    "# Save uniprot_features file\n",
    "uniprot_features_filtered.to_csv(output_filter_hits, sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc39c53",
   "metadata": {},
   "source": [
    "## Reformat features file\n",
    "\n",
    "The features file from UniProt must be reformatted slightly to work well with ProteinCartography. We reformatted the file to fit with guidelines listed [here](https://github.com/Arcadia-Science/ProteinCartography#feature-file-main-columns).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd69b425-8b2c-45d0-a5f6-2b44c2cc34bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw features file\n",
    "\n",
    "uniprot_features_filtered = pd.read_csv(output_filter_hits, sep=\"\\t\")\n",
    "\n",
    "# Reformat lineage column\n",
    "\n",
    "lineage_string_splitter = lambda lineage_string: [\n",
    "    rank.split(\" (\")[0] for rank in lineage_string.split(\", \")\n",
    "]\n",
    "\n",
    "uniprot_features_filtered[\"Lineage\"] = uniprot_features_filtered[\n",
    "    \"Taxonomic lineage\"\n",
    "].apply(lineage_string_splitter)\n",
    "\n",
    "# Saves updated uniprot_features file\n",
    "\n",
    "uniprot_features_filtered.to_csv(\"../output/uniprot_features.tsv\", sep=\"\\t\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('2023-actin-embedding')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7feb7b648551b17321812410889dc113a13e3f7213a30852c19b0534c2deed0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
